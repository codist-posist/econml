{"cells": [{"cell_type": "markdown", "id": "9fa9ad07", "metadata": {}, "source": ["# 94_fig4_persistence_sensitivity\n", "\n", "Figure 4: compare temporary ξ shock persistence across two commitment runs (e.g., rho_tau=0.90 vs 0.99)."]}, {"cell_type": "code", "execution_count": null, "id": "54e27613", "metadata": {}, "outputs": [], "source": ["import os, sys, json, numpy as np, torch, matplotlib.pyplot as plt\nsys.path.append(\"..\")\n\nfrom src.config import ModelParams\nfrom src.io_utils import load_json, load_npz, load_torch, load_selected_run, find_latest_run_dir\nfrom src.deqn import PolicyNetwork\n\nART = os.path.join(\"..\",\"artifacts\",\"runs\")\n\ndef get_run(policy: str) -> str:\n    rd = load_selected_run(ART, policy)\n    if rd is None:\n        rd = find_latest_run_dir(ART, policy)\n    if rd is None:\n        raise RuntimeError(f\"No runs found for policy={policy} under {ART}\")\n    return rd\n\ndef _parse_dtype(s: str):\n    if s is None:\n        return torch.float32\n    if isinstance(s, torch.dtype):\n        return s\n    s = str(s)\n    if \"float64\" in s:\n        return torch.float64\n    if \"float32\" in s:\n        return torch.float32\n    if \"bfloat16\" in s:\n        return torch.bfloat16\n    return torch.float32\n\ndef load_params_from_run(run_dir: str, *, device=\"cpu\"):\n    cfg = load_json(os.path.join(run_dir, \"config.json\"))\n    p = cfg.get(\"params\", {})\n    dtype = _parse_dtype(p.get(\"dtype\"))\n    dev = device if device is not None else p.get(\"device\",\"cpu\")\n    keep = {k:v for k,v in p.items() if k in ModelParams.__dataclass_fields__}\n    keep[\"device\"] = dev\n    keep[\"dtype\"] = dtype\n    return ModelParams(**keep).to_torch()\n\ndef load_net_from_run(run_dir: str, d_in: int, d_out: int):\n    cfg = load_json(os.path.join(run_dir, \"config.json\"))\n    tc = cfg.get(\"train_cfg\", {})\n    hidden = tuple(tc.get(\"hidden_layers\", (512,512)))\n    activation = tc.get(\"activation\", \"selu\")\n    net = PolicyNetwork(d_in, d_out, hidden=hidden, activation=activation)\n    state = load_torch(os.path.join(run_dir, \"weights.pt\"), map_location=\"cpu\")\n    # state is usually a plain state_dict\n    if isinstance(state, dict) and \"state_dict\" in state:\n        state = state[\"state_dict\"]\n    net.load_state_dict(state)\n    net.eval()\n    return net\n\n# --- paper reporting helpers ---\nann = lambda x: 400.0*x  # annualized percent (quarterly -> annual)\n"]}, {"cell_type": "code", "execution_count": null, "id": "89620cdc", "metadata": {}, "outputs": [], "source": ["from src.steady_states import solve_commitment_sss_from_policy_switching\nfrom src.experiments import DeterministicPathSpec, simulate_deterministic_path, calibrate_xi_jump_to_match_pi_impact\n\nROOT = os.path.join(\"..\",\"artifacts\",\"runs\",\"commitment\")\n\ndef list_runs(root):\n    if not os.path.isdir(root): return []\n    runs = [os.path.join(root,d) for d in os.listdir(root) if os.path.isdir(os.path.join(root,d))]\n    runs.sort(key=lambda p: os.path.getmtime(p), reverse=True)\n    return runs\n\nruns = list_runs(ROOT)\nRUN_A = None\nRUN_B = None\nif RUN_A is None or RUN_B is None:\n    if len(runs) < 2:\n        raise RuntimeError(\"Need at least two commitment runs in artifacts/runs/commitment (trained with different rho_tau).\")\n    RUN_A, RUN_B = runs[0], runs[1]\n\nprint(\"RUN_A:\", RUN_A)\nprint(\"RUN_B:\", RUN_B)\n\nparamsA = load_params_from_run(RUN_A)\nparamsB = load_params_from_run(RUN_B)\nnetA = load_net_from_run(RUN_A, 7, 13)\nnetB = load_net_from_run(RUN_B, 7, 13)\n\nsssA = solve_commitment_sss_from_policy_switching(paramsA, netA)\nsssB = solve_commitment_sss_from_policy_switching(paramsB, netB)\n\nx0A = torch.tensor([[float(sssA.by_regime[0][\"Delta_prev\"]), float(sssA.by_regime[0][\"logA\"]), float(sssA.by_regime[0][\"loggtilde\"]), float(sssA.by_regime[0][\"xi\"]), 0.0,\n                     float(sssA.by_regime[0][\"vartheta_prev\"]), float(sssA.by_regime[0][\"varrho_prev\"])]], dtype=torch.float32)\nx0B = torch.tensor([[float(sssB.by_regime[0][\"Delta_prev\"]), float(sssB.by_regime[0][\"logA\"]), float(sssB.by_regime[0][\"loggtilde\"]), float(sssB.by_regime[0][\"xi\"]), 0.0,\n                     float(sssB.by_regime[0][\"vartheta_prev\"]), float(sssB.by_regime[0][\"varrho_prev\"])]], dtype=torch.float32)\n\nT=40\ntarget_pi0 = 0.01\n\nxiA = calibrate_xi_jump_to_match_pi_impact(paramsA, \"commitment\", netA, x0=x0A, target_pi0=target_pi0, horizon_T=1)\nxiB = calibrate_xi_jump_to_match_pi_impact(paramsB, \"commitment\", netB, x0=x0B, target_pi0=target_pi0, horizon_T=1)\n\nx0A2 = x0A.clone(); x0A2[:,3] += xiA\nx0B2 = x0B.clone(); x0B2[:,3] += xiB\n\nspec = DeterministicPathSpec(T=T, epsA=0.0, epsg=0.0, epst=0.0, regime_path=None)\npathA = simulate_deterministic_path(paramsA, \"commitment\", netA, x0=x0A2, spec=spec, compute_implied_i=True)\npathB = simulate_deterministic_path(paramsB, \"commitment\", netB, x0=x0B2, spec=spec, compute_implied_i=True)\n\nt=np.arange(T+1)\nplt.figure()\nplt.plot(t, ann(pathA[\"pi\"][:,0]), label=f\"Run A (rho_tau={paramsA.rho_tau})\")\nplt.plot(t, ann(pathB[\"pi\"][:,0]), label=f\"Run B (rho_tau={paramsB.rho_tau})\", linestyle=\"--\")\nplt.axhline(0, linewidth=1)\nplt.title(\"Figure 4: π persistence (matched impact)\")\nplt.xlabel(\"t\"); plt.ylabel(\"π\"); plt.legend(); plt.show()\n"]}, {"cell_type": "code", "metadata": {}, "outputs": [], "source": ["# Paper Figure 4 strict requirement: run in the no-regime model.\n", "# Enforce eta_bar=0 and p12=p21=0 for both runs.\n", "def _require_no_regimes(params, label):\n", "    if float(params.eta_bar) != 0.0 or float(params.p12) != 0.0 or float(params.p21) != 0.0:\n", "        raise RuntimeError(\n", "            f\"{label}: Figure 4 in the paper is defined for the no-regime model only (eta_bar=0, p12=0, p21=0). \"\n", "            f\"Current values: eta_bar={params.eta_bar}, p12={params.p12}, p21={params.p21}.\"\n", "        )\n", "\n", "_require_no_regimes(paramsA, 'Run A')\n", "_require_no_regimes(paramsB, 'Run B')\n"]}], "metadata": {}, "nbformat": 4, "nbformat_minor": 5}