{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9fa9ad07",
   "metadata": {},
   "source": [
    "# 94_fig4_persistence_sensitivity\n",
    "\n",
    "Figure 4: compare temporary Î¾ shock persistence across two commitment runs (e.g., rho_tau=0.90 vs 0.99)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54e27613",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, json, numpy as np, torch, matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "\n",
    "def _find_project_root():\n",
    "    here = pathlib.Path.cwd().resolve()\n",
    "    for p in [here, *here.parents]:\n",
    "        if (p / \"src\").is_dir():\n",
    "            return p\n",
    "    # Common Google Colab clone location\n",
    "    cand = pathlib.Path(\"/content/econml\")\n",
    "    if (cand / \"src\").is_dir():\n",
    "        return cand\n",
    "    raise RuntimeError(\"Could not find project root containing src/. If on Colab, clone repo to /content/econml.\")\n",
    "\n",
    "PROJECT_ROOT = _find_project_root()\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "from src.config import ModelParams\n",
    "from src.io_utils import load_json, load_npz, load_torch, load_selected_run, find_latest_run_dir\n",
    "from src.deqn import PolicyNetwork\n",
    "\n",
    "ART = str(PROJECT_ROOT / \"artifacts\" / \"runs\")\n",
    "COMPUTE_DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Compute device:\", COMPUTE_DEVICE)\n",
    "\n",
    "def get_run(policy: str) -> str:\n",
    "    rd = load_selected_run(ART, policy)\n",
    "    if rd is None:\n",
    "        rd = find_latest_run_dir(ART, policy)\n",
    "    if rd is None:\n",
    "        raise RuntimeError(f\"No runs found for policy={policy} under {ART}\")\n",
    "    return rd\n",
    "\n",
    "def _parse_dtype(s: str):\n",
    "    if s is None:\n",
    "        return torch.float32\n",
    "    if isinstance(s, torch.dtype):\n",
    "        return s\n",
    "    s = str(s)\n",
    "    if \"float64\" in s:\n",
    "        return torch.float64\n",
    "    if \"float32\" in s:\n",
    "        return torch.float32\n",
    "    if \"bfloat16\" in s:\n",
    "        return torch.bfloat16\n",
    "    return torch.float32\n",
    "\n",
    "def load_params_from_run(run_dir: str, *, device=None):\n",
    "    cfg = load_json(os.path.join(run_dir, \"config.json\"))\n",
    "    p = cfg.get(\"params\", {})\n",
    "    dtype = _parse_dtype(p.get(\"dtype\"))\n",
    "    dev = device if device is not None else COMPUTE_DEVICE\n",
    "    keep = {k:v for k,v in p.items() if k in ModelParams.__dataclass_fields__}\n",
    "    keep[\"device\"] = dev\n",
    "    keep[\"dtype\"] = dtype\n",
    "    return ModelParams(**keep).to_torch()\n",
    "\n",
    "def load_net_from_run(run_dir: str, d_in: int, d_out: int, *, device=None):\n",
    "    cfg = load_json(os.path.join(run_dir, \"config.json\"))\n",
    "    tc = cfg.get(\"train_cfg\", {})\n",
    "    hidden = tuple(tc.get(\"hidden_layers\", (512,512)))\n",
    "    activation = tc.get(\"activation\", \"selu\")\n",
    "    p = cfg.get(\"params\", {})\n",
    "    net_dtype = _parse_dtype(p.get(\"dtype\"))\n",
    "    dev = device if device is not None else COMPUTE_DEVICE\n",
    "    net = PolicyNetwork(d_in, d_out, hidden=hidden, activation=activation).to(device=dev, dtype=net_dtype)\n",
    "    state = load_torch(os.path.join(run_dir, \"weights.pt\"), map_location=\"cpu\")\n",
    "    # state is usually a plain state_dict\n",
    "    if isinstance(state, dict) and \"state_dict\" in state:\n",
    "        state = state[\"state_dict\"]\n",
    "    net.load_state_dict(state)\n",
    "    net.eval()\n",
    "    return net\n",
    "\n",
    "# --- paper reporting helpers ---\n",
    "ann = lambda x: 400.0*x  # annualized percent (quarterly -> annual)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89620cdc",
   "metadata": {},
   "outputs": [],
   "source": "from src.steady_states import solve_commitment_sss_from_policy_switching\nfrom src.experiments import DeterministicPathSpec, simulate_deterministic_path\n\nART_ROOT = str(PROJECT_ROOT / \"artifacts\")\nROOT = os.path.join(ART_ROOT, \"runs\", \"commitment\")\n\nTARGET_RHO_A = 0.90\nTARGET_RHO_B = 0.99\nRHO_TOL = 1e-10\nSHOCK_STD_MULT = 1.0  # one-sigma temporary cost-push shock at t=0 for both calibrations\n\n\ndef _has_weights(run_dir: str) -> bool:\n    return os.path.exists(os.path.join(run_dir, \"weights.pt\")) or os.path.exists(os.path.join(run_dir, \"weights_best.pt\"))\n\n\ndef list_runs(root):\n    if not os.path.isdir(root):\n        return []\n    runs = []\n    for d in os.listdir(root):\n        rd = os.path.join(root, d)\n        if os.path.isdir(rd) and _has_weights(rd):\n            runs.append(rd)\n    runs.sort(key=lambda q: os.path.getmtime(q), reverse=True)\n    return runs\n\n\ndef _is_no_regime(params) -> bool:\n    return float(params.eta_bar) == 0.0 and float(params.p12) == 0.0 and float(params.p21) == 0.0\n\n\ndef _is_target_rho(v: float, target: float) -> bool:\n    return abs(float(v) - float(target)) <= RHO_TOL\n\n\ndef _pick_target_pair(candidates, rho_a: float, rho_b: float):\n    cache = {}\n\n    def getp(run_dir):\n        if run_dir not in cache:\n            cache[run_dir] = load_params_from_run(run_dir)\n        return cache[run_dir]\n\n    run_a = None\n    run_b = None\n    params_a = None\n    params_b = None\n\n    for rd in candidates:\n        p = getp(rd)\n        if not _is_no_regime(p):\n            continue\n        if run_a is None and _is_target_rho(p.rho_tau, rho_a):\n            run_a, params_a = rd, p\n        if run_b is None and _is_target_rho(p.rho_tau, rho_b):\n            run_b, params_b = rd, p\n        if run_a is not None and run_b is not None:\n            break\n\n    if run_a is None or run_b is None:\n        return None, None, None, None\n    return run_a, run_b, params_a, params_b\n\n\nruns = []\nselected = load_selected_run(ART_ROOT, \"commitment\")\nif selected is not None and os.path.isdir(selected) and _has_weights(selected):\n    runs.append(selected)\nfor rd in list_runs(ROOT):\n    if rd not in runs:\n        runs.append(rd)\n\nRUN_A = None\nRUN_B = None\n\nif RUN_A is None or RUN_B is None:\n    RUN_A, RUN_B, paramsA, paramsB = _pick_target_pair(runs, TARGET_RHO_A, TARGET_RHO_B)\n    if RUN_A is None:\n        raise RuntimeError(\n            f\"Need two no-regime commitment runs with rho_tau={TARGET_RHO_A} and rho_tau={TARGET_RHO_B}.\"\n        )\nelse:\n    if not (_has_weights(RUN_A) and _has_weights(RUN_B)):\n        raise RuntimeError(\"RUN_A/RUN_B must point to runs containing weights.pt or weights_best.pt.\")\n    paramsA = load_params_from_run(RUN_A)\n    paramsB = load_params_from_run(RUN_B)\n\nprint(\"RUN_A:\", RUN_A)\nprint(\"RUN_B:\", RUN_B)\n\n\ndef _require_no_regimes(params, label):\n    if float(params.eta_bar) != 0.0 or float(params.p12) != 0.0 or float(params.p21) != 0.0:\n        raise RuntimeError(\n            f\"{label}: Figure 4 is defined for no-regime model only (eta_bar=0, p12=0, p21=0). \"\n            f\"Current values: eta_bar={params.eta_bar}, p12={params.p12}, p21={params.p21}.\"\n        )\n\n\n_require_no_regimes(paramsA, \"Run A\")\n_require_no_regimes(paramsB, \"Run B\")\nif not _is_target_rho(paramsA.rho_tau, TARGET_RHO_A):\n    raise RuntimeError(f\"Run A must have rho_tau={TARGET_RHO_A}, got {paramsA.rho_tau}.\")\nif not _is_target_rho(paramsB.rho_tau, TARGET_RHO_B):\n    raise RuntimeError(f\"Run B must have rho_tau={TARGET_RHO_B}, got {paramsB.rho_tau}.\")\n\nnetA = load_net_from_run(RUN_A, 7, 13)\nnetB = load_net_from_run(RUN_B, 7, 13)\n\nsssA = solve_commitment_sss_from_policy_switching(paramsA, netA)\nsssB = solve_commitment_sss_from_policy_switching(paramsB, netB)\n\nx0A = torch.tensor([[float(sssA.by_regime[0][\"Delta_prev\"]), float(sssA.by_regime[0][\"logA\"]), float(sssA.by_regime[0][\"loggtilde\"]), float(sssA.by_regime[0][\"xi\"]), 0.0,\n                     float(sssA.by_regime[0][\"vartheta_prev\"]), float(sssA.by_regime[0][\"varrho_prev\"])]], dtype=torch.float32)\nx0B = torch.tensor([[float(sssB.by_regime[0][\"Delta_prev\"]), float(sssB.by_regime[0][\"logA\"]), float(sssB.by_regime[0][\"loggtilde\"]), float(sssB.by_regime[0][\"xi\"]), 0.0,\n                     float(sssB.by_regime[0][\"vartheta_prev\"]), float(sssB.by_regime[0][\"varrho_prev\"])]], dtype=torch.float32)\n\nT = 40\n\n# One-time temporary shock at t=0 (same size in sigma-units for both runs), then deterministic decay.\nxiA = SHOCK_STD_MULT * float(paramsA.sigma_tau)\nxiB = SHOCK_STD_MULT * float(paramsB.sigma_tau)\nx0A2 = x0A.clone(); x0A2[:, 3] += xiA\nx0B2 = x0B.clone(); x0B2[:, 3] += xiB\n\nspec = DeterministicPathSpec(T=T, epsA=0.0, epsg=0.0, epst=0.0, regime_path=None)\npathA = simulate_deterministic_path(paramsA, \"commitment\", netA, x0=x0A2, spec=spec, compute_implied_i=True)\npathB = simulate_deterministic_path(paramsB, \"commitment\", netB, x0=x0B2, spec=spec, compute_implied_i=True)\n\nt = np.arange(T + 1)\nplt.figure()\nplt.plot(t, ann(pathA[\"pi\"][:, 0]), label=f\"rho_tau={paramsA.rho_tau:.2f}\")\nplt.plot(t, ann(pathB[\"pi\"][:, 0]), label=f\"rho_tau={paramsB.rho_tau:.2f}\", linestyle=\"--\")\nplt.axhline(0, linewidth=1)\nplt.title(\"Figure 4: pi persistence (temporary cost-push shock)\")\nplt.xlabel(\"Time in quarters\")\nplt.ylabel(\"Annualized percent\")\nplt.legend()\nplt.show()\n"
  },
  {
   "cell_type": "code",
   "id": "b008f011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checks for no-regime configuration and distinct rho_tau are enforced in the previous cell before any simulation.\n"
   ],
   "execution_count": null
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
