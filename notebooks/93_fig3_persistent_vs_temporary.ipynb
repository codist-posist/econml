{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b576aa80",
   "metadata": {},
   "source": [
    "# 93_fig3_persistent_vs_temporary\n",
    "\n",
    "Figure 3: persistent regime switch vs temporary Î¾ shock with matched inflation impact (commitment or discretion)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da358cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, json, numpy as np, torch, matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "\n",
    "def _find_project_root():\n",
    "    here = pathlib.Path.cwd().resolve()\n",
    "    for p in [here, *here.parents]:\n",
    "        if (p / \"src\").is_dir():\n",
    "            return p\n",
    "    # Common Google Colab clone location\n",
    "    cand = pathlib.Path(\"/content/econml\")\n",
    "    if (cand / \"src\").is_dir():\n",
    "        return cand\n",
    "    raise RuntimeError(\"Could not find project root containing src/. If on Colab, clone repo to /content/econml.\")\n",
    "\n",
    "PROJECT_ROOT = _find_project_root()\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "from src.config import ModelParams\n",
    "from src.io_utils import load_json, load_npz, load_torch, load_selected_run, find_latest_run_dir\n",
    "from src.deqn import PolicyNetwork\n",
    "\n",
    "ART = str(PROJECT_ROOT / \"artifacts\" / \"runs\")\n",
    "\n",
    "def get_run(policy: str) -> str:\n",
    "    rd = load_selected_run(ART, policy)\n",
    "    if rd is None:\n",
    "        rd = find_latest_run_dir(ART, policy)\n",
    "    if rd is None:\n",
    "        raise RuntimeError(f\"No runs found for policy={policy} under {ART}\")\n",
    "    return rd\n",
    "\n",
    "def _parse_dtype(s: str):\n",
    "    if s is None:\n",
    "        return torch.float32\n",
    "    if isinstance(s, torch.dtype):\n",
    "        return s\n",
    "    s = str(s)\n",
    "    if \"float64\" in s:\n",
    "        return torch.float64\n",
    "    if \"float32\" in s:\n",
    "        return torch.float32\n",
    "    if \"bfloat16\" in s:\n",
    "        return torch.bfloat16\n",
    "    return torch.float32\n",
    "\n",
    "def load_params_from_run(run_dir: str, *, device=\"cpu\"):\n",
    "    cfg = load_json(os.path.join(run_dir, \"config.json\"))\n",
    "    p = cfg.get(\"params\", {})\n",
    "    dtype = _parse_dtype(p.get(\"dtype\"))\n",
    "    dev = device if device is not None else p.get(\"device\",\"cpu\")\n",
    "    keep = {k:v for k,v in p.items() if k in ModelParams.__dataclass_fields__}\n",
    "    keep[\"device\"] = dev\n",
    "    keep[\"dtype\"] = dtype\n",
    "    return ModelParams(**keep).to_torch()\n",
    "\n",
    "def load_net_from_run(run_dir: str, d_in: int, d_out: int):\n",
    "    cfg = load_json(os.path.join(run_dir, \"config.json\"))\n",
    "    tc = cfg.get(\"train_cfg\", {})\n",
    "    hidden = tuple(tc.get(\"hidden_layers\", (512,512)))\n",
    "    activation = tc.get(\"activation\", \"selu\")\n",
    "    p = cfg.get(\"params\", {})\n",
    "    net_dtype = _parse_dtype(p.get(\"dtype\"))\n",
    "    net = PolicyNetwork(d_in, d_out, hidden=hidden, activation=activation).to(device=\"cpu\", dtype=net_dtype)\n",
    "    state = load_torch(os.path.join(run_dir, \"weights.pt\"), map_location=\"cpu\")\n",
    "    # state is usually a plain state_dict\n",
    "    if isinstance(state, dict) and \"state_dict\" in state:\n",
    "        state = state[\"state_dict\"]\n",
    "    net.load_state_dict(state)\n",
    "    net.eval()\n",
    "    return net\n",
    "\n",
    "# --- paper reporting helpers ---\n",
    "ann = lambda x: 400.0*x  # annualized percent (quarterly -> annual)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0c4925",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.steady_states import solve_commitment_sss_from_policy_switching, solve_discretion_sss_from_policy_switching\n",
    "from src.experiments import DeterministicPathSpec, simulate_deterministic_path, calibrate_xi_jump_to_match_pi_impact\n",
    "\n",
    "POLICY = \"commitment\"  # or \"discretion\"\n",
    "run_dir = get_run(POLICY)\n",
    "params = load_params_from_run(run_dir)\n",
    "\n",
    "if POLICY == \"commitment\":\n",
    "    net = load_net_from_run(run_dir, 7, 13)\n",
    "    sss = solve_commitment_sss_from_policy_switching(params, net)\n",
    "    x0 = torch.tensor([[float(sss.by_regime[0][\"Delta_prev\"]), float(sss.by_regime[0][\"logA\"]), float(sss.by_regime[0][\"loggtilde\"]), float(sss.by_regime[0][\"xi\"]), 0.0,\n",
    "                        float(sss.by_regime[0][\"vartheta_prev\"]), float(sss.by_regime[0][\"varrho_prev\"])]], dtype=torch.float32)\n",
    "else:\n",
    "    net = load_net_from_run(run_dir, 5, 11)\n",
    "    sss = solve_discretion_sss_from_policy_switching(params, net)\n",
    "    x0 = torch.tensor([[float(sss.by_regime[0][\"Delta_prev\"]), float(sss.by_regime[0][\"logA\"]), float(sss.by_regime[0][\"loggtilde\"]), float(sss.by_regime[0][\"xi\"]), 0.0]], dtype=torch.float32)\n",
    "\n",
    "T = 40\n",
    "spec_switch = DeterministicPathSpec(T=T, epsA=0.0, epsg=0.0, epst=0.0, regime_path=[0] + [1] * T)\n",
    "path_switch = simulate_deterministic_path(params, POLICY, net, x0=x0, spec=spec_switch, compute_implied_i=True)\n",
    "\n",
    "# With regime_path=[0]+[1]*T, the forced switch applies to x_{t+1}; impact appears at index 1.\n",
    "target_pi0 = float(path_switch[\"pi\"][1].mean())\n",
    "\n",
    "xi_jump = calibrate_xi_jump_to_match_pi_impact(\n",
    "    params, POLICY, net, x0=x0, target_pi0=target_pi0, horizon_T=1, regime_path=[0, 0]\n",
    ")\n",
    "x0_xi = x0.clone(); x0_xi[:, 3] += xi_jump\n",
    "spec_temp = DeterministicPathSpec(T=T, epsA=0.0, epsg=0.0, epst=0.0, regime_path=[0] * (T + 1))\n",
    "path_temp = simulate_deterministic_path(params, POLICY, net, x0=x0_xi, spec=spec_temp, compute_implied_i=True)\n",
    "\n",
    "# Align timelines so both series start at impact period (plot t=0).\n",
    "pi_switch = path_switch[\"pi\"][1:, 0]   # length T\n",
    "pi_temp = path_temp[\"pi\"][:T, 0]       # length T\n",
    "\n",
    "# Price levels normalized to 1 at impact date.\n",
    "def price_level_from_pi(pi_series: np.ndarray) -> np.ndarray:\n",
    "    out = np.ones(len(pi_series) + 1, dtype=np.float64)\n",
    "    if len(pi_series) > 0:\n",
    "        out[1:] = np.cumprod(1.0 + np.asarray(pi_series, dtype=np.float64))\n",
    "    return out\n",
    "\n",
    "P_switch = price_level_from_pi(pi_switch)\n",
    "P_temp = price_level_from_pi(pi_temp)\n",
    "\n",
    "t = np.arange(T)\n",
    "tP = np.arange(T + 1)\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(11, 4))\n",
    "\n",
    "ax[0].plot(t, ann(pi_switch), label=\"Persistent (regime switch)\")\n",
    "ax[0].plot(t, ann(pi_temp), label=\"Temporary xi shock\", linestyle=\"--\")\n",
    "ax[0].axhline(0.0, linewidth=1)\n",
    "ax[0].set_title(\"Figure 3a: Inflation paths (matched impact)\")\n",
    "ax[0].set_xlabel(\"t\")\n",
    "ax[0].set_ylabel(\"Annualized percent\")\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].plot(tP, P_switch, label=\"Persistent (regime switch)\")\n",
    "ax[1].plot(tP, P_temp, label=\"Temporary xi shock\", linestyle=\"--\")\n",
    "ax[1].set_title(\"Figure 3b: Price level\")\n",
    "ax[1].set_xlabel(\"t\")\n",
    "ax[1].set_ylabel(\"Index (normalized at impact)\")\n",
    "ax[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Matched impact (aligned t=0) target_pi0:\", target_pi0, \"xi_jump:\", xi_jump)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
