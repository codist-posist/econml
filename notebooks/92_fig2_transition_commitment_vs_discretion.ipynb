{"cells": [{"cell_type": "markdown", "id": "cdd70551", "metadata": {}, "source": ["# 92_fig2_transition_commitment_vs_discretion\n", "\n", "Figure 2: forced transition normalâ†’bad, commitment vs discretion, deterministic innovations (eps=0)."]}, {"cell_type": "code", "execution_count": null, "id": "9ca3f005", "metadata": {}, "outputs": [], "source": "import os, sys, json, numpy as np, torch, matplotlib.pyplot as plt\nimport pathlib\n\ndef _find_project_root():\n    here = pathlib.Path.cwd().resolve()\n    for p in [here, *here.parents]:\n        if (p / \"src\").is_dir():\n            return p\n    # Common Google Colab clone location\n    cand = pathlib.Path(\"/content/econml\")\n    if (cand / \"src\").is_dir():\n        return cand\n    raise RuntimeError(\"Could not find project root containing src/. If on Colab, clone repo to /content/econml.\")\n\nPROJECT_ROOT = _find_project_root()\nif str(PROJECT_ROOT) not in sys.path:\n    sys.path.insert(0, str(PROJECT_ROOT))\n\nfrom src.config import ModelParams\nfrom src.io_utils import load_json, load_npz, load_torch, load_selected_run, find_latest_run_dir\nfrom src.deqn import PolicyNetwork\n\nART = str(PROJECT_ROOT / \"artifacts\" / \"runs\")\n\ndef get_run(policy: str) -> str:\n    rd = load_selected_run(ART, policy)\n    if rd is None:\n        rd = find_latest_run_dir(ART, policy)\n    if rd is None:\n        raise RuntimeError(f\"No runs found for policy={policy} under {ART}\")\n    return rd\n\ndef _parse_dtype(s: str):\n    if s is None:\n        return torch.float32\n    if isinstance(s, torch.dtype):\n        return s\n    s = str(s)\n    if \"float64\" in s:\n        return torch.float64\n    if \"float32\" in s:\n        return torch.float32\n    if \"bfloat16\" in s:\n        return torch.bfloat16\n    return torch.float32\n\ndef load_params_from_run(run_dir: str, *, device=\"cpu\"):\n    cfg = load_json(os.path.join(run_dir, \"config.json\"))\n    p = cfg.get(\"params\", {})\n    dtype = _parse_dtype(p.get(\"dtype\"))\n    dev = device if device is not None else p.get(\"device\",\"cpu\")\n    keep = {k:v for k,v in p.items() if k in ModelParams.__dataclass_fields__}\n    keep[\"device\"] = dev\n    keep[\"dtype\"] = dtype\n    return ModelParams(**keep).to_torch()\n\ndef load_net_from_run(run_dir: str, d_in: int, d_out: int):\n    cfg = load_json(os.path.join(run_dir, \"config.json\"))\n    tc = cfg.get(\"train_cfg\", {})\n    hidden = tuple(tc.get(\"hidden_layers\", (512,512)))\n    activation = tc.get(\"activation\", \"selu\")\n    net = PolicyNetwork(d_in, d_out, hidden=hidden, activation=activation)\n    state = load_torch(os.path.join(run_dir, \"weights.pt\"), map_location=\"cpu\")\n    # state is usually a plain state_dict\n    if isinstance(state, dict) and \"state_dict\" in state:\n        state = state[\"state_dict\"]\n    net.load_state_dict(state)\n    net.eval()\n    return net\n\n# --- paper reporting helpers ---\nann = lambda x: 400.0*x  # annualized percent (quarterly -> annual)\n"}, {"cell_type": "code", "execution_count": null, "id": "45f13a08", "metadata": {}, "outputs": [], "source": ["from src.steady_states import solve_commitment_sss_from_policy, solve_discretion_sss_from_policy, solve_efficient_sss\n", "from src.experiments import DeterministicPathSpec, simulate_deterministic_path\n", "\n", "run_comm = get_run(\"commitment\")\n", "run_disc = get_run(\"discretion\")\n", "\n", "params_comm = load_params_from_run(run_comm)\n", "params_disc = load_params_from_run(run_disc)\n", "\n", "# In the paper, policies are compared under the same calibration.\n", "def _assert_same_calibration(p1, p2, *, atol=1e-12):\n", "    fields = [k for k in ModelParams.__dataclass_fields__.keys() if k not in (\"device\", \"dtype\")]\n", "    diffs = []\n", "    for k in fields:\n", "        v1 = getattr(p1, k)\n", "        v2 = getattr(p2, k)\n", "        if isinstance(v1, (int, float)) and isinstance(v2, (int, float)):\n", "            if abs(float(v1) - float(v2)) > atol:\n", "                diffs.append((k, v1, v2))\n", "        else:\n", "            if v1 != v2:\n", "                diffs.append((k, v1, v2))\n", "    if diffs:\n", "        details = \", \".join([f\"{k}: commitment={a}, discretion={b}\" for k, a, b in diffs])\n", "        raise RuntimeError(\n", "            \"Figure 2 requires identical calibration across commitment/discretion runs. \"\n", "            f\"Differences found: {details}\"\n", "        )\n", "\n", "_assert_same_calibration(params_comm, params_disc)\n", "params = params_comm\n", "\n", "net_comm = load_net_from_run(run_comm, 7, 13)\n", "net_disc = load_net_from_run(run_disc, 5, 11)\n", "\n", "comm_sss = solve_commitment_sss_from_policy(params, net_comm)\n", "disc_sss = solve_discretion_sss_from_policy(params, net_disc)\n", "\n", "x0_comm = torch.tensor([[float(comm_sss.by_regime[0][\"Delta_prev\"]), float(comm_sss.by_regime[0][\"logA\"]), float(comm_sss.by_regime[0][\"loggtilde\"]), float(comm_sss.by_regime[0][\"xi\"]), 0.0,\n", "                         float(comm_sss.by_regime[0][\"vartheta_prev\"]),\n", "                         float(comm_sss.by_regime[0][\"varrho_prev\"])]], dtype=torch.float32)\n", "x0_disc = torch.tensor([[float(disc_sss.by_regime[0][\"Delta_prev\"]), float(disc_sss.by_regime[0][\"logA\"]), float(disc_sss.by_regime[0][\"loggtilde\"]), float(disc_sss.by_regime[0][\"xi\"]), 0.0]], dtype=torch.float32)\n", "\n", "T = 40\n", "spec = DeterministicPathSpec(T=T, epsA=0.0, epsg=0.0, epst=0.0, regime_path=[0] + [1] * T)\n", "\n", "path_comm = simulate_deterministic_path(params, \"commitment\", net_comm, x0=x0_comm, spec=spec, compute_implied_i=True)\n", "path_disc = simulate_deterministic_path(params, \"discretion\", net_disc, x0=x0_disc, spec=spec, compute_implied_i=True)\n", "\n", "# regime_path=[0]+[1]*T sets s_{t+1}; switch impact is at index 1.\n", "pi_comm_all = path_comm[\"pi\"][:, 0]\n", "pi_disc_all = path_disc[\"pi\"][:, 0]\n", "i_comm_all = path_comm[\"i\"][:, 0]\n", "i_disc_all = path_disc[\"i\"][:, 0]\n", "c_comm_all = path_comm[\"c\"][:, 0]\n", "c_disc_all = path_disc[\"c\"][:, 0]\n", "\n", "# Real rate uses realized next inflation.\n", "r_comm_all = ((1.0 + i_comm_all[:-1]) / (1.0 + pi_comm_all[1:])) - 1.0\n", "r_disc_all = ((1.0 + i_disc_all[:-1]) / (1.0 + pi_disc_all[1:])) - 1.0\n", "\n", "# align all plotted series to switch impact at t=0 and common length\n", "n = min(len(r_comm_all) - 1, len(r_disc_all) - 1)\n", "if n <= 0:\n", "    raise RuntimeError(\"Figure 2 alignment failed: too short deterministic paths.\")\n", "\n", "pi_comm = pi_comm_all[1:1 + n]\n", "pi_disc = pi_disc_all[1:1 + n]\n", "r_comm = r_comm_all[1:1 + n]\n", "r_disc = r_disc_all[1:1 + n]\n", "\n", "eff = solve_efficient_sss(params)\n", "c_hat = float(eff[\"c_hat\"])\n", "x_comm = np.log(c_comm_all[1:1 + n]) - np.log(c_hat)\n", "x_disc = np.log(c_disc_all[1:1 + n]) - np.log(c_hat)\n", "\n", "t = np.arange(n)\n", "\n", "fig, ax = plt.subplots(1, 3, figsize=(14, 4))\n", "\n", "ax[0].plot(t, ann(pi_comm), label=\"Commitment\")\n", "ax[0].plot(t, ann(pi_disc), label=\"Discretion\", linestyle=\"--\")\n", "ax[0].axhline(0.0, linewidth=1)\n", "ax[0].set_title(\"Figure 2a: Inflation\")\n", "ax[0].set_xlabel(\"t\")\n", "ax[0].set_ylabel(\"Annualized percent\")\n", "ax[0].legend()\n", "\n", "ax[1].plot(t, 100.0 * x_comm, label=\"Commitment\")\n", "ax[1].plot(t, 100.0 * x_disc, label=\"Discretion\", linestyle=\"--\")\n", "ax[1].axhline(0.0, linewidth=1)\n", "ax[1].set_title(\"Figure 2b: Output gap\")\n", "ax[1].set_xlabel(\"t\")\n", "ax[1].set_ylabel(\"Percent\")\n", "ax[1].legend()\n", "\n", "ax[2].plot(t, ann(r_comm), label=\"Commitment\")\n", "ax[2].plot(t, ann(r_disc), label=\"Discretion\", linestyle=\"--\")\n", "ax[2].axhline(0.0, linewidth=1)\n", "ax[2].set_title(\"Figure 2c: Real rate\")\n", "ax[2].set_xlabel(\"t\")\n", "ax[2].set_ylabel(\"Annualized percent\")\n", "ax[2].legend()\n", "\n", "plt.tight_layout()\n", "plt.show()\n"]}], "metadata": {}, "nbformat": 4, "nbformat_minor": 5}