{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7896388",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, json\n",
    "import numpy as np\n",
    "import torch\n",
    "import pathlib\n",
    "\n",
    "def _find_project_root():\n",
    "    here = pathlib.Path.cwd().resolve()\n",
    "    for p in [here, *here.parents]:\n",
    "        if (p / \"src\").is_dir():\n",
    "            return p\n",
    "    # Common Google Colab clone location\n",
    "    cand = pathlib.Path(\"/content/econml\")\n",
    "    if (cand / \"src\").is_dir():\n",
    "        return cand\n",
    "    raise RuntimeError(\"Could not find project root containing src/. If on Colab, clone repo to /content/econml.\")\n",
    "\n",
    "PROJECT_ROOT = _find_project_root()\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "from src.config import ModelParams, TrainConfig\n",
    "from src.deqn import PolicyNetwork, Trainer, simulate_paths\n",
    "from src.io_utils import make_run_dir, save_run_metadata, save_selected_run, pack_config, save_torch, save_csv, save_json, save_npz, ensure_dir\n",
    "from src.metrics import residual_quality\n",
    "\n",
    "# ---------- config ----------\n",
    "ARTIFACTS_ROOT = str(PROJECT_ROOT / \"artifacts\")\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using device:\", DEVICE)\n",
    "params = ModelParams(device=DEVICE, dtype=torch.float32)\n",
    "\n",
    "cfg_seed = 0\n",
    "cfg_probe = TrainConfig.mid(seed=cfg_seed)\n",
    "run_dir = make_run_dir(ARTIFACTS_ROOT, \"commitment\", tag=cfg_probe.mode, seed=cfg_probe.seed)\n",
    "cfg = TrainConfig.mid(seed=cfg_seed, run_dir=run_dir, artifacts_root=ARTIFACTS_ROOT)\n",
    "\n",
    "save_run_metadata(run_dir, pack_config(params, cfg, extra={\"policy\":\"commitment\"}))\n",
    "print(\"Run dir:\", run_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61842e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "rbar = None  # commitment does not use rbar_by_regime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d222a1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Timeless commitment (paper): do NOT require precomputed SSS to initialize multipliers.\n",
    "# We use a short transient (burn-in) only for post-training simulations/diagnostics to focus on the ergodic region.\n",
    "commit_init = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1d570f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---------- model ----------\n",
    "d_in, d_out = 7, 13\n",
    "net = PolicyNetwork(d_in, d_out, hidden=cfg.hidden_layers, activation=cfg.activation)\n",
    "\n",
    "trainer = Trainer(\n",
    "    params=params,\n",
    "    cfg=cfg,\n",
    "    policy=\"commitment\",\n",
    "    net=net,\n",
    "    rbar_by_regime=rbar if \"commitment\"==\"mod_taylor\" else None,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d2f491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No SSS-based initialization for timeless commitment.\n",
    "commit_init = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d687a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---------- train ----------\n",
    "losses = trainer.train(\n",
    "    commitment_sss=None,\n",
    "    n_path=cfg.n_path,\n",
    "    n_paths_per_step=cfg.n_paths_per_step,\n",
    ")\n",
    "\n",
    "# save weights and log\n",
    "save_torch(os.path.join(run_dir, \"weights.pt\"), trainer.net.state_dict())\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({\"iter\": np.arange(len(losses)), \"loss\": losses})\n",
    "save_csv(os.path.join(run_dir, \"train_log.csv\"), df)\n",
    "\n",
    "# quality on a fresh validation batch sampled from the model's simulated state distribution\n",
    "# Discretion residuals require autograd through Delta-derivative terms.\n",
    "ctx = torch.enable_grad() if trainer.policy == \"discretion\" else torch.inference_mode()\n",
    "with ctx:\n",
    "    x_val = trainer.simulate_initial_state(int(cfg.val_size), commitment_sss=None)\n",
    "    # optional short burn-in for validation states (kept small; training itself is path-based)\n",
    "    val_burn = int(getattr(cfg, \"val_burn_in\", 200))\n",
    "    for _ in range(val_burn):\n",
    "        x_val = trainer._step_state(x_val)\n",
    "    resid = trainer._residuals(x_val).detach().cpu().numpy()\n",
    "q = residual_quality(resid, tol=getattr(cfg, \"report_tol\", 1e-3))\n",
    "save_json(os.path.join(run_dir, \"train_quality.json\"), q)\n",
    "print(\"Train quality:\", q)\n",
    "\n",
    "# optional: mark this run as selected for results notebook\n",
    "save_selected_run(ARTIFACTS_ROOT, trainer.policy, run_dir)\n",
    "\n",
    "# Commitment SSS and timeless simulations are computed in the next cells.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18741503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Timeless commitment refinement ----------\n",
    "# 1) Compute commitment SSS from the first-pass trained network.\n",
    "# 2) Fine-tune training with commitment multipliers initialized at those SSS values.\n",
    "# 3) Recompute SSS and diagnostics from the refined network.\n",
    "from dataclasses import replace\n",
    "from src.steady_states import solve_commitment_sss_from_policy\n",
    "from src.sanity_checks import fixed_point_check, residuals_check_switching_consistent\n",
    "\n",
    "# 1) Initial timeless fixed point from first-pass network\n",
    "comm_sss_seed = solve_commitment_sss_from_policy(params, trainer.net)\n",
    "\n",
    "# 2) Timeless fine-tune (phase-2 only)\n",
    "timeless_finetune_steps = int(cfg.phase2.steps)\n",
    "cfg_tl = replace(\n",
    "    cfg,\n",
    "    phase1=replace(cfg.phase1, steps=0),\n",
    "    phase2=replace(cfg.phase2, steps=timeless_finetune_steps),\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    params=params,\n",
    "    cfg=cfg_tl,\n",
    "    policy=\"commitment\",\n",
    "    net=trainer.net,\n",
    "    rbar_by_regime=None,\n",
    ")\n",
    "\n",
    "ft_losses = trainer.train(\n",
    "    commitment_sss=comm_sss_seed.by_regime,\n",
    "    n_path=cfg_tl.n_path,\n",
    "    n_paths_per_step=cfg_tl.n_paths_per_step,\n",
    ")\n",
    "\n",
    "# Persist refined network and fine-tune log\n",
    "save_torch(os.path.join(run_dir, \"weights.pt\"), trainer.net.state_dict())\n",
    "import pandas as pd\n",
    "save_csv(\n",
    "    os.path.join(run_dir, \"train_log_timeless_finetune.csv\"),\n",
    "    pd.DataFrame({\"iter\": np.arange(len(ft_losses)), \"loss\": ft_losses}),\n",
    ")\n",
    "\n",
    "if len(ft_losses):\n",
    "    print(f\"Timeless fine-tune done: steps={len(ft_losses)}, best_loss={min(ft_losses):.3e}\")\n",
    "else:\n",
    "    print(\"Timeless fine-tune done: no extra steps were run.\")\n",
    "\n",
    "# Refresh train quality for the refined network\n",
    "with torch.inference_mode():\n",
    "    x_val = trainer.simulate_initial_state(int(cfg.val_size), commitment_sss=comm_sss_seed.by_regime)\n",
    "    val_burn = int(getattr(cfg, \"val_burn_in\", 200))\n",
    "    for _ in range(val_burn):\n",
    "        x_val = trainer._step_state(x_val)\n",
    "    resid = trainer._residuals(x_val).detach().cpu().numpy()\n",
    "q = residual_quality(resid, tol=getattr(cfg, \"report_tol\", 1e-3))\n",
    "save_json(os.path.join(run_dir, \"train_quality.json\"), q)\n",
    "print(\"Train quality (after timeless fine-tune):\", q)\n",
    "\n",
    "# 3) Final commitment SSS and sanity checks from refined network\n",
    "comm_sss = solve_commitment_sss_from_policy(params, trainer.net)\n",
    "save_json(os.path.join(run_dir, 'sss_policy_fixed_point.json'), {'policy':'commitment','by_regime': comm_sss.by_regime})\n",
    "\n",
    "print('=== COMMITMENT SSS (switching-consistent, includes lagged multipliers; timeless perspective) ===')\n",
    "for _s in sorted(comm_sss.by_regime.keys()):\n",
    "    print(f'Regime {_s}:')\n",
    "    for _k,_v in comm_sss.by_regime[_s].items():\n",
    "        print(f'{_k:>20}: {_v}')\n",
    "\n",
    "fp = fixed_point_check(params, trainer.net, policy='commitment', sss_by_regime=comm_sss.by_regime)\n",
    "rc = residuals_check_switching_consistent(params, trainer.net, policy='commitment', sss_by_regime=comm_sss.by_regime)\n",
    "print('Fixed-regime one-step check max |x_next-x| by regime (NOT Table-2 SSS):', {k:v.max_abs_state_diff for k,v in fp.items()})\n",
    "print('Switching-consistent residual check max |res| by regime:', {k:v.max_abs_residual for k,v in rc.items()})\n",
    "print('Residual keys:', list(next(iter(rc.values())).residuals.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e785b796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Save sanity checks ----------\n",
    "save_json(os.path.join(run_dir, 'sanity_checks.json'), {\n",
    "    'policy': 'commitment',\n",
    "    'fixed_regime_one_step_max_abs_state_diff': {int(k): float(v.max_abs_state_diff) for k,v in fp.items()},\n",
    "    'residual_max_abs': {int(k): float(v.max_abs_residual) for k,v in rc.items()},\n",
    "    'residuals_by_regime': {int(k): {kk: float(vv) for kk,vv in v.residuals.items()} for k,v in rc.items()},\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f7ae0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Simulate (timeless commitment: start from SSS incl. lagged multipliers) ----------\n",
    "# This produces sim_paths.npz used by Table 2 / figures.\n",
    "B_sim = 2048\n",
    "T_sim = 6000\n",
    "burn_in_sim = 1000\n",
    "\n",
    "x0_sim = trainer.simulate_initial_state(B_sim, commitment_sss=comm_sss.by_regime)\n",
    "sim = simulate_paths(\n",
    "    params=params,\n",
    "    policy=\"commitment\",\n",
    "    net=trainer.net,\n",
    "    T=T_sim,\n",
    "    burn_in=burn_in_sim,\n",
    "    x0=x0_sim,\n",
    "    compute_implied_i=True,\n",
    "    gh_n=7,\n",
    "    thin=1,\n",
    "    show_progress=True,\n",
    "    store_states=False,\n",
    ")\n",
    "\n",
    "save_npz(os.path.join(run_dir, \"sim_paths.npz\"), **sim)\n",
    "print(\"Saved sim_paths:\", os.path.join(run_dir, \"sim_paths.npz\"))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
