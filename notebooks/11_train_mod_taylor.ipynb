{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff0a6846",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, json\n",
    "import numpy as np\n",
    "import torch\n",
    "import pathlib\n",
    "\n",
    "def _find_project_root():\n",
    "    here = pathlib.Path.cwd().resolve()\n",
    "    for p in [here, *here.parents]:\n",
    "        if (p / \"src\").is_dir():\n",
    "            return p\n",
    "    # Common Google Colab clone location\n",
    "    cand = pathlib.Path(\"/content/econml\")\n",
    "    if (cand / \"src\").is_dir():\n",
    "        return cand\n",
    "    raise RuntimeError(\"Could not find project root containing src/. If on Colab, clone repo to /content/econml.\")\n",
    "\n",
    "PROJECT_ROOT = _find_project_root()\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "from src.config import ModelParams, TrainConfig\n",
    "from src.deqn import PolicyNetwork, Trainer, simulate_paths\n",
    "from src.io_utils import make_run_dir, save_run_metadata, save_selected_run, pack_config, save_torch, save_csv, save_json, save_npz, ensure_dir\n",
    "from src.metrics import residual_quality\n",
    "\n",
    "# ---------- config ----------\n",
    "ARTIFACTS_ROOT = str(PROJECT_ROOT / \"artifacts\")\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using device:\", DEVICE)\n",
    "params = ModelParams(device=DEVICE, dtype=torch.float32)\n",
    "\n",
    "cfg_seed = 0\n",
    "cfg_probe = TrainConfig.mid(seed=cfg_seed)\n",
    "run_dir = make_run_dir(ARTIFACTS_ROOT, \"mod_taylor\", tag=cfg_probe.mode, seed=cfg_probe.seed)\n",
    "cfg = TrainConfig.mid(seed=cfg_seed, run_dir=run_dir, artifacts_root=ARTIFACTS_ROOT)\n",
    "\n",
    "save_run_metadata(run_dir, pack_config(params, cfg, extra={\"policy\":\"mod_taylor\"}))\n",
    "print(\"Run dir:\", run_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af835c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from src.steady_states import solve_flexprice_sss, export_rbar_tensor\n",
    "flex = solve_flexprice_sss(params)\n",
    "rbar = export_rbar_tensor(params, flex)\n",
    "save_json(os.path.join(run_dir, \"flex_ref.json\"), {\"by_regime\": flex.by_regime, \"rbar_by_regime\": rbar.detach().cpu().tolist()})\n",
    "\n",
    "print(\"=== FLEX SSS (by regime) ===\")\n",
    "for _s in sorted(flex.by_regime.keys()):\n",
    "    print(f\"Regime {_s}:\")\n",
    "    for _k,_v in flex.by_regime[_s].items():\n",
    "        print(f\"{_k:>20}: {_v}\")\n",
    "print(\"=== RBAR (by regime) ===\")\n",
    "for _s, _v in enumerate(rbar.detach().cpu().tolist()):\n",
    "    print(f\"Regime {_s}: {_v}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6cd5570",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# (SSS for modified Taylor rule is computed AFTER training as a fixed point of the trained policy.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac608054",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---------- model ----------\n",
    "d_in, d_out = 5, 8\n",
    "net = PolicyNetwork(d_in, d_out, hidden=cfg.hidden_layers, activation=cfg.activation)\n",
    "\n",
    "trainer = Trainer(\n",
    "    params=params,\n",
    "    cfg=cfg,\n",
    "    policy=\"mod_taylor\",\n",
    "    net=net,\n",
    "    rbar_by_regime=rbar if \"mod_taylor\"==\"mod_taylor\" else None,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50653591",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---------- train ----------\n",
    "losses = trainer.train(\n",
    "    commitment_sss=None,\n",
    "    n_path=cfg.n_path,\n",
    "    n_paths_per_step=cfg.n_paths_per_step,\n",
    ")\n",
    "\n",
    "# save weights and log\n",
    "save_torch(os.path.join(run_dir, \"weights.pt\"), trainer.net.state_dict())\n",
    "import pandas as pd\n",
    "df = pd.DataFrame({\"iter\": np.arange(len(losses)), \"loss\": losses})\n",
    "save_csv(os.path.join(run_dir, \"train_log.csv\"), df)\n",
    "\n",
    "# quality on a fresh validation batch sampled from the model's simulated state distribution\n",
    "# Discretion residuals require autograd through Delta-derivative terms.\n",
    "ctx = torch.enable_grad() if trainer.policy == \"discretion\" else torch.inference_mode()\n",
    "with ctx:\n",
    "    x_val = trainer.simulate_initial_state(int(cfg.val_size), commitment_sss=None)\n",
    "    # optional short burn-in for validation states (kept small; training itself is path-based)\n",
    "    val_burn = int(getattr(cfg, \"val_burn_in\", 200))\n",
    "    for _ in range(val_burn):\n",
    "        x_val = trainer._step_state(x_val)\n",
    "    resid = trainer._residuals(x_val).detach().cpu().numpy()\n",
    "q = residual_quality(resid, tol=getattr(cfg, \"report_tol\", 1e-3))\n",
    "save_json(os.path.join(run_dir, \"train_quality.json\"), q)\n",
    "print(\"Train quality:\", q)\n",
    "\n",
    "# optional: mark this run as selected for results notebook\n",
    "save_selected_run(ARTIFACTS_ROOT, trainer.policy, run_dir)\n",
    "\n",
    "# ---------- simulate ergodic paths ----------\n",
    "x0 = trainer.simulate_initial_state(512, commitment_sss=None)\n",
    "sim = simulate_paths(\n",
    "    params=params,\n",
    "    policy=trainer.policy,\n",
    "    net=trainer.net,\n",
    "    T=20000,\n",
    "    burn_in=2000,\n",
    "    x0=x0,\n",
    "    rbar_by_regime=rbar if trainer.policy==\"mod_taylor\" else None,\n",
    "    compute_implied_i=False,\n",
    "    gh_n=3,\n",
    "    thin=10,\n",
    "    show_progress=True,\n",
    ")\n",
    "save_npz(os.path.join(run_dir, \"sim_paths.npz\"), **sim)\n",
    "print(\"Saved sim_paths to:\", os.path.join(run_dir, \"sim_paths.npz\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61f25e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.sss_from_policy import switching_policy_sss_by_regime_from_policy\n",
    "\n",
    "sss_all = switching_policy_sss_by_regime_from_policy(params, trainer.net, policy=\"mod_taylor\")\n",
    "sss = sss_all.by_regime\n",
    "save_json(os.path.join(run_dir, \"sss_policy_fixed_point.json\"), {\"policy\":\"mod_taylor\",\"by_regime\": sss})\n",
    "\n",
    "print(\"=== MODIFIED TAYLOR SSS (switching-consistent) ===\")\n",
    "for _s in [0,1]:\n",
    "    print(f\"Regime {_s}:\")\n",
    "    for _k,_v in sss[_s].items():\n",
    "        print(f\"{_k:>20}: {_v}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247a146c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Sanity checks (fixed point + residuals) ----------\n",
    "from src.sss_from_policy import switching_policy_sss_by_regime_from_policy\n",
    "from src.sanity_checks import fixed_point_check, residuals_check\n",
    "mt_sss_pol = switching_policy_sss_by_regime_from_policy(params, trainer.net, policy='mod_taylor')\n",
    "fp = fixed_point_check(params, trainer.net, policy='mod_taylor', sss_by_regime=mt_sss_pol.by_regime)\n",
    "rc = residuals_check(params, trainer.net, policy='mod_taylor', sss_by_regime=mt_sss_pol.by_regime)\n",
    "print('Fixed point max |x_next-x| by regime:', {k:v.max_abs_state_diff for k,v in fp.items()})\n",
    "print('Residual check max |res| by regime:', {k:v.max_abs_residual for k,v in rc.items()})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835d8d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Save sanity checks ----------\n",
    "save_json(os.path.join(run_dir, 'sanity_checks.json'), {\n",
    "    'policy': 'mod_taylor',\n",
    "    'fixed_point_max_abs_state_diff': {int(k): float(v.max_abs_state_diff) for k,v in fp.items()},\n",
    "    'residual_max_abs': {int(k): float(v.max_abs_residual) for k,v in rc.items()},\n",
    "    'residuals_by_regime': {int(k): {kk: float(vv) for kk,vv in v.residuals.items()} for k,v in rc.items()},\n",
    "})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
