{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d383c506",
   "metadata": {},
   "source": [
    "# 90_results_analysis\n",
    "\n",
    "Aggregates results across policies: loads **selected** (or **latest**) runs, summarizes **training quality**, and prints/saves SSS outputs for Table 2-style reporting. Figures are reproduced in separate notebooks (91/92/93/94/96/99/100).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7fe66fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, json, numpy as np, pandas as pd\n",
    "import torch\n",
    "\n",
    "import pathlib\n",
    "\n",
    "def _find_project_root():\n",
    "    here = pathlib.Path.cwd().resolve()\n",
    "    for p in [here, *here.parents]:\n",
    "        if (p / \"src\").is_dir():\n",
    "            return p\n",
    "    # Common Google Colab clone location\n",
    "    cand = pathlib.Path(\"/content/econml\")\n",
    "    if (cand / \"src\").is_dir():\n",
    "        return cand\n",
    "    raise RuntimeError(\"Could not find project root containing src/. If on Colab, clone repo to /content/econml.\")\n",
    "\n",
    "PROJECT_ROOT = _find_project_root()\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "from src.io_utils import load_selected_run, find_latest_run_dir, load_json\n",
    "from src.table2_builder import build_table2, save_table2_csv\n",
    "\n",
    "ARTIFACTS_ROOT = os.environ.get(\"ARTIFACTS_ROOT\", str(PROJECT_ROOT / \"artifacts\"))\n",
    "print(\"ARTIFACTS_ROOT:\", ARTIFACTS_ROOT)\n",
    "POLICIES = ['taylor','mod_taylor','discretion','commitment']\n",
    "\n",
    "def get_run(policy: str) -> str | None:\n",
    "    rd = load_selected_run(ARTIFACTS_ROOT, policy)\n",
    "    if rd is None:\n",
    "        rd = find_latest_run_dir(ARTIFACTS_ROOT, policy)\n",
    "    return rd\n",
    "\n",
    "RUNS = {p: get_run(p) for p in POLICIES}\n",
    "RUNS\n",
    "\n",
    "\n",
    "# --- paper reporting helpers ---\n",
    "ann = lambda x: 400.0*x  # annualized percent (quarterly -> annual)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a459aedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_artifacts(run_dir: str | None):\n",
    "    if run_dir is None:\n",
    "        return {'run_dir': None, 'sss': None, 'sss_path': None, 'train_quality': None, 'sim_paths_path': None}\n",
    "    out = {'run_dir': run_dir}\n",
    "\n",
    "    # Prefer policy fixed-point SSS (used by train notebooks), fall back to legacy sss.json.\n",
    "    sss_candidates = ['sss_policy_fixed_point.json', 'sss.json']\n",
    "    sss_path = None\n",
    "    for name in sss_candidates:\n",
    "        cand = os.path.join(run_dir, name)\n",
    "        if os.path.exists(cand):\n",
    "            sss_path = cand\n",
    "            break\n",
    "    out['sss'] = load_json(sss_path) if sss_path is not None else None\n",
    "    out['sss_path'] = sss_path\n",
    "\n",
    "    tq_path = os.path.join(run_dir, 'train_quality.json')\n",
    "    out['train_quality'] = load_json(tq_path) if os.path.exists(tq_path) else None\n",
    "    sp_path = os.path.join(run_dir, 'sim_paths.npz')\n",
    "    out['sim_paths_path'] = sp_path if os.path.exists(sp_path) else None\n",
    "    return out\n",
    "\n",
    "ARTS = {p: load_artifacts(RUNS[p]) for p in POLICIES}\n",
    "ARTS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f62b0d8",
   "metadata": {},
   "source": [
    "## Training quality summary\n",
    "\n",
    "Quality is computed from residuals on a fresh validation batch sampled from the trainer's simulated validation distribution (RMS / max abs / share of states where all equations are below tolerance)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09cf2f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "for p in POLICIES:\n",
    "    tq = ARTS[p]['train_quality'] or {}\n",
    "    rows.append({\n",
    "        'policy': p,\n",
    "        'run_dir': ARTS[p]['run_dir'],\n",
    "        'rms': tq.get('rms'),\n",
    "        'max_abs': tq.get('max_abs'),\n",
    "        'share_all_lt_tol': tq.get('share_all_lt_tol'),\n",
    "        'tol': tq.get('tol'),\n",
    "        'val_size': tq.get('val_size'),\n",
    "    })\n",
    "pd.DataFrame(rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c67adacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.io_utils import load_json\n",
    "\n",
    "def _load_sanity(run_dir: str | None):\n",
    "    if run_dir is None:\n",
    "        return None\n",
    "    p = os.path.join(run_dir, 'sanity_checks.json')\n",
    "    return load_json(p) if os.path.exists(p) else None\n",
    "\n",
    "rows = []\n",
    "for p in POLICIES:\n",
    "    run_dir = ARTS[p]['run_dir']\n",
    "    sc = _load_sanity(run_dir)\n",
    "    tq = ARTS[p]['train_quality'] or {}\n",
    "    tol = tq.get('tol', None)\n",
    "    # Residual tolerance: use training tol if available, else a conservative default\n",
    "    tol_res = float(tol) if tol is not None else 1e-4\n",
    "    # Fixed-point tolerance: typically tighter; scale with residual tol\n",
    "    tol_fp = max(1e-8, tol_res * 1e-2)\n",
    "    if sc is None:\n",
    "        rows.append({'policy': p, 'run_dir': run_dir, 'sanity_file': False,\n",
    "                     'fp_max_abs': None, 'res_max_abs': None,\n",
    "                     'pass_fp': None, 'pass_res': None, 'tol_fp': tol_fp, 'tol_res': tol_res})\n",
    "        continue\n",
    "    # expected schema from training notebooks\n",
    "    fp = sc.get('fixed_point_max_abs_state_diff', sc.get('fixed_point', {}))\n",
    "    rm = sc.get('residual_max_abs', sc.get('residual_max', {}))\n",
    "    # take worst over regimes if present\n",
    "    def worst(d):\n",
    "        if isinstance(d, dict) and len(d):\n",
    "            try:\n",
    "                return float(max(d.values()))\n",
    "            except Exception:\n",
    "                pass\n",
    "        return None\n",
    "    fp_max = worst(fp)\n",
    "    res_max = worst(rm)\n",
    "    rows.append({\n",
    "        'policy': p,\n",
    "        'run_dir': run_dir,\n",
    "        'sanity_file': True,\n",
    "        'fp_max_abs': fp_max,\n",
    "        'res_max_abs': res_max,\n",
    "        'tol_fp': tol_fp,\n",
    "        'tol_res': tol_res,\n",
    "        'pass_fp': (fp_max is not None and fp_max <= tol_fp),\n",
    "        'pass_res': (res_max is not None and res_max <= tol_res),\n",
    "    })\n",
    "\n",
    "df_sanity = pd.DataFrame(rows)\n",
    "display(df_sanity)\n",
    "if df_sanity['sanity_file'].all():\n",
    "    bad = df_sanity[(df_sanity['pass_fp'] == False) | (df_sanity['pass_res'] == False)]\n",
    "    if len(bad):\n",
    "        print('\\nSanity-check FAIL for:')\n",
    "        display(bad[['policy','fp_max_abs','tol_fp','res_max_abs','tol_res','run_dir']])\n",
    "    else:\n",
    "        print('All sanity-checks PASS (fixed point + residuals).')\n",
    "else:\n",
    "    print('Some runs are missing sanity_checks.json (see table above).')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362618c6",
   "metadata": {},
   "source": [
    "## Steady-state results (SSS)\n",
    "\n",
    "Loads `sss.json` produced by each training notebook. This is the input for Table 2 construction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ab3b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for p in POLICIES:\n",
    "    print(\"\\n==============================\")\n",
    "    print(\"POLICY:\", p)\n",
    "    sss = ARTS[p][\"sss\"]\n",
    "    if sss is None:\n",
    "        print(\"Missing sss.json\")\n",
    "        continue\n",
    "    # Print compactly\n",
    "    if \"by_regime\" in sss:\n",
    "        for s in [\"0\",\"1\",0,1]:\n",
    "            if s in sss[\"by_regime\"]:\n",
    "                reg = sss[\"by_regime\"][s]\n",
    "                print(f\"Regime {s}: keys={list(reg.keys())[:10]} ...\")\n",
    "        print(\"by_regime:\", sss[\"by_regime\"])\n",
    "    else:\n",
    "        print(sss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bbc3917",
   "metadata": {},
   "source": [
    "## Ergodic moments (optional)\n",
    "\n",
    "If `sim_paths.npz` exists in each run, compute simple ergodic moments by regime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c7cac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Table 2 (paper) + Taylor variants ----\n",
    "df_table2 = build_table2(ARTIFACTS_ROOT, device='cpu', include_rules=True)\n",
    "display(df_table2)\n",
    "\n",
    "csv_path = save_table2_csv(df_table2, ARTIFACTS_ROOT, filename='table2_reproduced.csv')\n",
    "print('Saved:', csv_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc535b3b",
   "metadata": {},
   "source": [
    "# Notes:\n",
    "# - Rates and inflation are annualized percent (400x quarterly net).\n",
    "# - Output gap is in percent (100 * log(c/c_hat)).\n",
    "# - Real rate uses realized next inflation: r_t = (1+i_t)/(1+pi_{t+1}) - 1.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
